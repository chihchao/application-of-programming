{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM+jw7nX2WmLh7MDbWBP4/m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chihchao/application-of-programming/blob/main/web_system_ask_gemini_with_gradio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio google-generativeai"
      ],
      "metadata": {
        "id": "LcC_1WNBkpIG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f79f766-dd9c-4288-eee8-592b3807092f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.1/54.1 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m323.1/323.1 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from google import genai\n",
        "\n",
        "client = genai.Client(api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    contents=[\"How does AI work?\"]\n",
        ")\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "4tM33SAUlVtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from google import genai\n",
        "\n",
        "client = genai.Client(api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "\n",
        "def ask_gemini(question):\n",
        "    response = client.models.generate_content(\n",
        "        model=\"gemini-2.0-flash\",\n",
        "        contents=[question]\n",
        "    )\n",
        "    return response.text\n",
        "\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## Gemini å•ç­”ç³»çµ±\")\n",
        "    question = gr.Textbox(label=\"è«‹è¼¸å…¥ä½ çš„å•é¡Œ\")\n",
        "    ask_button = gr.Button(\"è©¢å• Gemini\")\n",
        "    answer = gr.Textbox(label=\"Gemini å›ç­”\", interactive=False)\n",
        "    ask_button.click(fn=ask_gemini, inputs=question, outputs=answer)\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "nw-a9QcpmDtf",
        "outputId": "6d095f79-055e-4932-ab56-f3948fb255f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://99eadd18190fb6b428.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://99eadd18190fb6b428.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsjULwaPjY5i"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "from google import genai\n",
        "from google.colab import userdata\n",
        "client = genai.Client(api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "\n",
        "# é è¨­å¯†ç¢¼\n",
        "PASSWORD = \"123456\"\n",
        "\n",
        "# å¯†ç¢¼é©—è­‰ç‹€æ…‹\n",
        "auth_status = {\"authenticated\": False}\n",
        "\n",
        "def verify_password(pw):\n",
        "    if pw == PASSWORD:\n",
        "        auth_status[\"authenticated\"] = True\n",
        "        return gr.update(visible=False), gr.update(visible=True), \"\"\n",
        "    else:\n",
        "        return gr.update(), gr.update(visible=False), \"âŒ å¯†ç¢¼éŒ¯èª¤ï¼Œè«‹å†è©¦ä¸€æ¬¡\"\n",
        "\n",
        "def ask_gemini(question):\n",
        "    if not auth_status[\"authenticated\"]:\n",
        "        return \"ğŸš« å°šæœªé€šéé©—è­‰\"\n",
        "    response = client.model.generate_content(question)\n",
        "    return response.text\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## ğŸ” è«‹è¼¸å…¥å¯†ç¢¼ä»¥ä½¿ç”¨ Gemini å•ç­”ç³»çµ±\")\n",
        "\n",
        "    with gr.Row():\n",
        "        password_input = gr.Textbox(type=\"password\", label=\"è¼¸å…¥å¯†ç¢¼\")\n",
        "        login_button = gr.Button(\"ç™»å…¥\")\n",
        "\n",
        "    login_status = gr.Textbox(label=\"\", interactive=False, show_label=False)\n",
        "\n",
        "    # å•ç­”å€å¡Š\n",
        "    with gr.Column(visible=False) as qa_section:\n",
        "        question = gr.Textbox(label=\"è«‹è¼¸å…¥ä½ çš„å•é¡Œ\")\n",
        "        answer = gr.Textbox(label=\"Gemini å›ç­”\", interactive=False)\n",
        "        ask_button = gr.Button(\"è©¢å• Gemini\")\n",
        "\n",
        "        ask_button.click(fn=ask_gemini, inputs=question, outputs=answer)\n",
        "\n",
        "    login_button.click(\n",
        "        fn=verify_password,\n",
        "        inputs=password_input,\n",
        "        outputs=[password_input, qa_section, login_status]\n",
        "    )\n",
        "\n",
        "demo.launch()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## å°è©±èŠå¤©"
      ],
      "metadata": {
        "id": "8AyPIy7daM7j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. ```requirements.txt```\n",
        "\n",
        "```python\n",
        "gradio\n",
        "google-genai\n",
        "```\n",
        "\n",
        "2. ```app.py```\n",
        "\n",
        "```from google.colab import userdata``` -> ```import os```\n",
        "\n",
        "```userdata.get``` -> ```os.getenv```"
      ],
      "metadata": {
        "id": "PqlhJGRYc1Qd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from google import genai\n",
        "\n",
        "from google.colab import userdata\n",
        "api_key=userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "client = genai.Client(api_key=api_key)\n",
        "\n",
        "# å»ºç«‹ chat ç‰©ä»¶\n",
        "chat = client.chats.create(model=\"gemini-2.0-flash\")\n",
        "\n",
        "# è™•ç†ä½¿ç”¨è€…è¼¸å…¥ä¸¦å›è¦†\n",
        "def respond(message, history):\n",
        "    response = chat.send_message(message)\n",
        "    return response.text\n",
        "\n",
        "# å»ºç«‹ Gradio ChatInterface\n",
        "demo = gr.ChatInterface(\n",
        "    fn=respond,\n",
        "    title=\"Gemini èŠå¤©æ©Ÿå™¨äººï¼ˆæ–°ç‰ˆ Client APIï¼‰\"\n",
        ")\n",
        "\n",
        "# å•Ÿå‹• Gradio App\n",
        "demo.launch()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "UuRso5hkaLss",
        "outputId": "29de1cf4-8054-4d7f-c7ab-2e4230e3eff4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gradio/chat_interface.py:338: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
            "  self.chatbot = Chatbot(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://b3548ff178fffbebd9.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://b3548ff178fffbebd9.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    }
  ]
}