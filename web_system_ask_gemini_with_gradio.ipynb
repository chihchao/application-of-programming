{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM+jw7nX2WmLh7MDbWBP4/m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chihchao/application-of-programming/blob/main/web_system_ask_gemini_with_gradio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio google-generativeai"
      ],
      "metadata": {
        "id": "LcC_1WNBkpIG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f79f766-dd9c-4288-eee8-592b3807092f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.1/54.1 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.1/323.1 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from google import genai\n",
        "\n",
        "client = genai.Client(api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    contents=[\"How does AI work?\"]\n",
        ")\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "4tM33SAUlVtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from google import genai\n",
        "\n",
        "client = genai.Client(api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "\n",
        "def ask_gemini(question):\n",
        "    response = client.models.generate_content(\n",
        "        model=\"gemini-2.0-flash\",\n",
        "        contents=[question]\n",
        "    )\n",
        "    return response.text\n",
        "\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## Gemini 問答系統\")\n",
        "    question = gr.Textbox(label=\"請輸入你的問題\")\n",
        "    ask_button = gr.Button(\"詢問 Gemini\")\n",
        "    answer = gr.Textbox(label=\"Gemini 回答\", interactive=False)\n",
        "    ask_button.click(fn=ask_gemini, inputs=question, outputs=answer)\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "nw-a9QcpmDtf",
        "outputId": "6d095f79-055e-4932-ab56-f3948fb255f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://99eadd18190fb6b428.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://99eadd18190fb6b428.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsjULwaPjY5i"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "from google import genai\n",
        "from google.colab import userdata\n",
        "client = genai.Client(api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "\n",
        "# 預設密碼\n",
        "PASSWORD = \"123456\"\n",
        "\n",
        "# 密碼驗證狀態\n",
        "auth_status = {\"authenticated\": False}\n",
        "\n",
        "def verify_password(pw):\n",
        "    if pw == PASSWORD:\n",
        "        auth_status[\"authenticated\"] = True\n",
        "        return gr.update(visible=False), gr.update(visible=True), \"\"\n",
        "    else:\n",
        "        return gr.update(), gr.update(visible=False), \"❌ 密碼錯誤，請再試一次\"\n",
        "\n",
        "def ask_gemini(question):\n",
        "    if not auth_status[\"authenticated\"]:\n",
        "        return \"🚫 尚未通過驗證\"\n",
        "    response = client.model.generate_content(question)\n",
        "    return response.text\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## 🔐 請輸入密碼以使用 Gemini 問答系統\")\n",
        "\n",
        "    with gr.Row():\n",
        "        password_input = gr.Textbox(type=\"password\", label=\"輸入密碼\")\n",
        "        login_button = gr.Button(\"登入\")\n",
        "\n",
        "    login_status = gr.Textbox(label=\"\", interactive=False, show_label=False)\n",
        "\n",
        "    # 問答區塊\n",
        "    with gr.Column(visible=False) as qa_section:\n",
        "        question = gr.Textbox(label=\"請輸入你的問題\")\n",
        "        answer = gr.Textbox(label=\"Gemini 回答\", interactive=False)\n",
        "        ask_button = gr.Button(\"詢問 Gemini\")\n",
        "\n",
        "        ask_button.click(fn=ask_gemini, inputs=question, outputs=answer)\n",
        "\n",
        "    login_button.click(\n",
        "        fn=verify_password,\n",
        "        inputs=password_input,\n",
        "        outputs=[password_input, qa_section, login_status]\n",
        "    )\n",
        "\n",
        "demo.launch()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 對話聊天"
      ],
      "metadata": {
        "id": "8AyPIy7daM7j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. ```requirements.txt```\n",
        "\n",
        "```python\n",
        "gradio\n",
        "google-genai\n",
        "```\n",
        "\n",
        "2. ```app.py```\n",
        "\n",
        "```from google.colab import userdata``` -> ```import os```\n",
        "\n",
        "```userdata.get``` -> ```os.getenv```"
      ],
      "metadata": {
        "id": "PqlhJGRYc1Qd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from google import genai\n",
        "\n",
        "from google.colab import userdata\n",
        "api_key=userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "client = genai.Client(api_key=api_key)\n",
        "\n",
        "# 建立 chat 物件\n",
        "chat = client.chats.create(model=\"gemini-2.0-flash\")\n",
        "\n",
        "# 處理使用者輸入並回覆\n",
        "def respond(message, history):\n",
        "    response = chat.send_message(message)\n",
        "    return response.text\n",
        "\n",
        "# 建立 Gradio ChatInterface\n",
        "demo = gr.ChatInterface(\n",
        "    fn=respond,\n",
        "    title=\"Gemini 聊天機器人（新版 Client API）\"\n",
        ")\n",
        "\n",
        "# 啟動 Gradio App\n",
        "demo.launch()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "UuRso5hkaLss",
        "outputId": "29de1cf4-8054-4d7f-c7ab-2e4230e3eff4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gradio/chat_interface.py:338: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
            "  self.chatbot = Chatbot(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://b3548ff178fffbebd9.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://b3548ff178fffbebd9.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    }
  ]
}